This script creates images for an optical character recognition (OCR) training program by generating 
  synthetic text images with a wide variety of augmentations and effects. It is specifically build to 
  not make assumptions about the lanaguge. This program will be used to generate training data based 
  on an ancient language that we don't know all the rules for. Here's a breakdown of the 
  process:

  Core Engine: OCRDataGenerator in src/main.py

  The main logic is encapsulated in the OCRDataGenerator class. It orchestrates the entire image 
  generation pipeline, from rendering text to applying complex augmentations.

  1. Configuration (`batch_config.py` and `batch_configs/`)

  The script is highly configurable through YAML files located in the `batch_configs/` directory. The `batch_config.py` module is responsible for parsing these files and setting up the generation parameters, such as image dimensions, font choices, text content, and the types and ranges of augmentations to be applied.

  2. Text Rendering and Layout (`canvas_placement.py`)

  The script first renders text onto a blank canvas. This is a highly configurable step, with the `canvas_placement.py` module handling the positioning of the text.

   * Multi-Directional Text: It can render text in four directions:
       * left_to_right (standard for English)
       * right_to_left (for languages like Arabic and Hebrew, using the bidi algorithm for correct 
         layout)
       * top_to_bottom (common in East Asian scripts)
       * bottom_to_top
   * Curved Text: It can render text along an arc or a sine wave, for both horizontal and vertical text.
   * Character Bounding Boxes: As each character is drawn, the script records its precise coordinates (the
      bounding box). This is the most critical piece of information for training the OCR model, as it 
     tells the model exactly where each character is located in the image.

  3. Simulating Real-World Text Imperfections

  To make the training data more realistic, the script applies several effects during the rendering 
  phase, using modules from src/:

   * Glyph Overlap (`glyph_overlap.py`): Instead of using standard font spacing, this module 
     programmatically reduces the space between characters to simulate tight kerning or overlapping 
     letters, a common occurrence in printed text.
   * Ink Bleed (`glyph_overlap.py`): This effect simulates the way ink spreads on paper, especially in 
     older or lower-quality prints. It's achieved by applying a Gaussian blur and other image filters.
   * 3D Effects (`text_3d_effects.py`): The script can add 3D effects to the text to mimic embossing, 
     engraving, or drop shadows. This helps the OCR model learn to read text that isn't flat.
   * Color Variation (`text_color.py`): The text color can be varied in several ways:
       * Uniform: All characters have the same color.
       * Per-Glyph: Each character has a different, random color.
       * Gradient: A smooth color gradient is applied across the text.

  4. Augmentations for Robustness (`augmentations.py`)

  After the initial text is rendered, the apply_augmentations function from src/augmentations.py 
  applies a random series of transformations to the image. This is crucial for training a robust OCR 
  model that can handle various real-world conditions. The augmentations include:

   * Geometric Distortions:
       * Perspective Warp: Skews the image to simulate a photo taken from an angle.
       * Elastic Distortion: Creates a "wavy" effect in the text.
       * Grid Distortion: Distorts the image using a grid.
       * Optical Distortion: Simulates lens distortion.
       * Rotation: Rotates the image by a small, random angle.
   * Image-Level Effects:
       * Backgrounds: The rendered text is pasted onto a random background image to train the model to 
         distinguish text from its surroundings.
       * Noise: Adds "salt and pepper" noise.
       * Blur: Applies a Gaussian blur.
       * Brightness and Contrast: Randomly adjusts the brightness and contrast.
       * Erosion/Dilation: Makes the text characters thinner or thicker.
       * Shadows: Adds a soft shadow effect.
       * Cutout: Randomly erases a rectangular portion of the image.

  Throughout the augmentation process, the character bounding boxes are continuously recalculated to 
  ensure they remain accurate.

  5. Output

  The final output of the script consists of two main parts:

   1. Generated Images: A set of PNG images, each containing a unique, synthetically generated line of 
      text with various augmentations.
   2. Label File (`labels.csv`): A CSV file that contains the ground truth for each image. Each row in the 
      CSV file corresponds to an image and stores the image's filename along with a JSON object containing 
      the text and the list of character bounding boxes.

  This combination of highly-augmented images and precise character-level annotations provides the 
  necessary data to train a powerful and accurate OCR model.